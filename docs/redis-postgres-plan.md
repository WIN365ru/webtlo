# План внедрения Redis и Postgres для WebTLO

Ниже — практичные точки ускорения для трёх кейсов: частые чтения, кеш внешних API, очередь/фоновые задачи.

## 1) Redis: кеш часто читаемых данных

### 1.1. Сводные показатели для отчётов

**Где:** сбор сводной статистики и списков раздач в `CreateReport`:
- `fillStoredValues()` считает агрегаты по форумам через запросы `Topics`/`Torrents`.
- `getStoredForumTopics()` загружает список раздач подраздела.
- `getClientsTopics()` собирает агрегацию по клиентам.

**Почему кеш:** эти данные используются при формировании отчётов, а также повторно в UI/cron. Можно кешировать результаты на короткое время (например, 2–5 минут) и инвалидировать при успешном обновлении данных.

**Ключи:**
- `report:stored-values` (общая сводка)
- `report:forum:{forumId}:topics` (раздачи подраздела)
- `report:clients-topics` (агрегаты по клиентам)

### 1.2. Кеш статусов/ответов API отчётов

**Где:** `KeepersReports::fetchApiReports()` — загрузка отчётов по подразделу из API отчётов.

**Почему кеш:** обращения к внешнему API могут быть дорогими и повторяются при отчетности/обновлениях. Кеш с TTL (например 5–15 минут) уменьшит нагрузку и ускорит генерацию отчётов.

**Ключи:**
- `api-report:subforum:{forumId}`

### 1.3. Кеш API ответов для «сторонних» и «разрегистрированных» раздач

**Где:**
- `TorrentsClients::updateUntracked()` — получение данных о раздачах по хешам (API).
- `TorrentsClients::updateUnregistered()` — получение данных о раздачах с форума.

**Почему кеш:** по многим хешам повторяющиеся запросы — кеш даст эффект при регулярных обновлениях.

**Ключи:**
- `api:topic-details:{hash}`
- `forum:topic:{topicId}`

## 2) Redis: очередь и фоновые задачи

### 2.1. Разделение update-потоков на фоновые задания

**Где:** `cron/update.php` запускает полный цикл обновления: форум, подразделы, детали, клиенты.

**Почему очередь:** можно разнести на фоновые задачи (каждый блок — отдельная задача), чтобы UI не блокировался и можно было повторять ошибки точечно.

**Идея реализации:**
- enqueue: `update:forum-tree`, `update:subsections`, `update:topic-details`, `update:clients`.
- worker: отдельный воркер обрабатывает задачи из Redis.

### 2.2. Отчёты как фоновые задания

**Где:** формирование/отправка отчётов: `SendKeeperReports` и `CreateReport`.

**Почему очередь:** отчёты могут занимать время; лучше запускать их асинхронно и показывать пользователю статус.

**Ключи:**
- `reports:send:forum:{forumId}`
- `reports:send:summary`

## 3) Postgres: когда это даст эффект

Postgres стоит рассматривать, если:
- количество данных выросло и SQLite становится узким местом (блокировки/конкурентные записи),
- запросы по таблицам `Topics`/`Torrents` становятся «тяжёлыми» из-за объёма или конкуренции,
- нужна масштабируемость, индексы и параллельные записи.

### 3.1. Потенциальные «тяжёлые» запросы

**Где:** в `CreateReport` выполняются агрегаты и выборки по `Topics`/`Torrents`. Эти запросы могут стать затратными при росте базы.

### 3.2. Миграция базовых таблиц

**Кандидаты на перенос:**
- `Topics`
- `Torrents`
- таблицы обновлений (`UpdateTime`) и производные таблицы для отчётов

## 4) Пример минимального MVP-подхода

1. Ввести Redis как кеш слоёв чтения (без изменения логики БД).
2. Добавить TTL-кеширование API ответов.
3. Выделить 1–2 критических процесса в очередь (например, полный update и генерация сводного отчёта).
4. Параллельно собрать метрики (время на API/SQL), чтобы понять, нужна ли миграция на Postgres.

## 5) Синхронизация и инвалидация кеша

Минимальная стратегия:
- очищать кеш при успешном завершении `update.php`;
- использовать короткие TTL (2–15 мин) для API и отчётных данных;
- использовать ключи версий (например, `cache:version`), чтобы одним инкрементом сбрасывать связанные ключи.
